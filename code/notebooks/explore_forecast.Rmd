---
title: "explore_reticulate"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(dplyr)
library(ggplot2)
```


# R

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
```


```{r}
# Connect to "jdbc:postgresql://postgres:5432/test"
con <- DBI::dbConnect(
  drv = RPostgres::Postgres(),
  host = "postgres",
  port=5432,
  dbname = "test",
  user = "test",
  password = "postgres"
  )
```

```{r}
pick_connection_id <- '871685900000000059MV'
pick_model_id = '451c7004-a0bb-4993-a437-771d2a489da0'
```

```{sql connection=con, output.var='model_df'}
select *
from whale_models
where connection_id = ?pick_connection_id
```

```{sql connection=con, output.var='actuals_df'}
select datetime, consumption
from whale_historical_ptu whp 
where connection_id = ?pick_connection_id
and consumption is not null
```


```{sql connection=con, output.var='backcast_df'}
select *
from whale_backcast wb
where model_id = ?pick_model_id
```

```{r}
backcast_df <- readr::read_csv(glue::glue("/usr/local/remote_data/whale_backcast/{backcast_df$id}.csv"))
```
```{r}
library(zoo)
library(dygraphs)
library(xts)
df_to_ts <- function(df){
  xts(
    x = df[,2:ncol(df)],
    order.by = df[,1]
    )
}

full_join(actuals_df, backcast_df, by = "datetime") %>% 
  df_to_ts() %>% 
  dygraph() %>% 
  dyRangeSelector()
```



# Basic working (outdated)

```{python}
import pandas
import pandas.io.sql as sqlio
import psycopg2
from pathlib import Path
import numpy as np

sys.path.append("/usr/local/modules")
from database_interaction import sql_file_to_df


sql_path = Path("/usr/local/sql")

conn = psycopg2.connect(
        host = "postgres",
        database = "test",
        user = "test",
        password = "postgres"
      )
      
      
dfoo = sql_file_to_df(
    conn = conn, 
    file = sql_path / "select_template" / "whale_ptu_factors_train_consumption.sql",
    params = {
        "connection_id": "871685900000000059MV",
        "date_from": "2021-01-01",
        "date_until": "2021-01-03"
      }
  )
```

```{python}

dfoo_ready = (
    dfoo
    .sort_values('datetime')
    .assign(temperature = lambda x: x["temperature"].interpolate())
    .assign(solar_radiation = lambda x: x["solar_radiation"].interpolate())
    # just to not include rows where `temperature` and `solar_radiation` are not interpolated
    .dropna(subset=['temperature', 'solar_radiation'])
)

```

```{python}
until_row = int(len(dfoo_ready)*(80/100))

train = dfoo_ready[:until_row]
test = dfoo_ready[until_row:]

train_features = ['temperature', 'solar_radiation', 'is_working_day', 'sfm_sin', 'sfm_cos', 'doy_sin', 'doy_cos']

c_features_train = train[train_features]

c_labels_train = np.array(train['consumption'])



```

```{python}
from sklearn.linear_model import LinearRegression

ml_model = LinearRegression().fit(c_features_train, c_labels_train)
```



